{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e4264b-262b-4792-8931-d6cd1566947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import akshare as ak\n",
    "from models.data_processing import DP\n",
    "from models.env_trading import FinanceTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "from matplotlib import font_manager\n",
    "# 设置字体为已安装的中文字体\n",
    "# 设置字体路径\n",
    "font_path = './models/msyh.ttc'  # 替换成你的字体路径\n",
    "font_prop = font_manager.FontProperties(fname=font_path)\n",
    "\n",
    "check_and_make_directories([TRAINED_MODEL_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f461c267-d3b6-45b0-a404-d28fbdfe1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models.data_preparing as dt_pre\n",
    "ak_list = pd.read_csv('./his_data/ak_stock_ticker_list.csv')['0'].to_list()\n",
    "ak_list = random.sample(ak_list, min(50, len(ak_list))) \n",
    "yf_list = pd.read_csv('./his_data/yf_stock_ticker_list.csv')['0'].to_list()\n",
    "yf_list = random.sample(yf_list, min(25, len(yf_list))) \n",
    "# bond_list = ak.bond_zh_hs_spot(start_page=\"1\", end_page=\"3\")[['代码', '名称']]\n",
    "# bond_list = list(set(bond_list['代码'].to_list()))\n",
    "# bond_list = random.sample(bond_list, min(50, len(bond_list))) \n",
    "# dt_pre.main(ak_list,yf_list,bond_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69533b3-6f45-462d-9a22-601ff9f9da9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finance Dimension: 113, State Space: 1248\n"
     ]
    }
   ],
   "source": [
    "import models.data_analysis as dt_anal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623fb63-a390-4e9a-bbe0-6433eb6956a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 10:00:49,483\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-12-23 10:00:51,149\tINFO worker.py:1652 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitializing Ray...\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m Finance Dimension: 113, State Space: 1248\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m Pretraining model from agent_a2c...\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m {'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m Using cpu device\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m Logging to results/a2c\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 124        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 100        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 4          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 500        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -160       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.0125     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 99         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -50.4      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -4.0666623 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 30.3       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 117       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 200       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 8         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 1000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.00354   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 199       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -2.47e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -7.793317 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 349       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 118       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 300       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 12        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 1500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.0326   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 299       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -2.1e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 31.267647 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 189       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 117        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 400        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 16         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 2000       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.0187     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 399        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.5e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -25.508596 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 287        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 99        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 500       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 25        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 2500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.0166    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 499       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 6.41e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 33.441914 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.76e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 98         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 600        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 30         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 3000       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.0299     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 599        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -9.36e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -33.779102 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 3.57e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 100        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 700        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 34         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 3500       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.00486   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 699        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -3.27e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -0.2939829 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 725        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m day: 484, episode: 10\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m end_total_asset: 2817618.27\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_reward: 1817618.27\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_cost: 48080.36\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_trades: 32412\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m Sharpe: 2.742\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 101       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 800       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 39        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 4000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.00248  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 799       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.13e+04 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 27.071022 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 6.88e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 103       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 900       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 43        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 4500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.000862 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 899       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 3.07e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 55.836674 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.68e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m ------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 101      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 1000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 49       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 5000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.00392 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 999      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 4.13e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 29.93434 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 897      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m ------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 96        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 1100      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 57        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 5500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.000614  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 1099      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 1.97e+04  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 19.350582 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.66e+04  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 85         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 1200       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 70         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 6000       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 1.19e-07   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 1199       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -6.8e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -25.570675 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.14e+04   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 79        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 1300      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 81        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 6500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.000747 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 1299      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -4.92e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 2.3704574 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 4.33e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 77        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 1400      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 90        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 7000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -9.82e-05 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 1399      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 919       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 145.21954 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 4.6e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 78        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 1500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 95        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 7500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.00136   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 1499      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 36.2      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 25.738596 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.09e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 79        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 1600      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 100       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 8000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -1.51e-05 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 1599      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -9.85e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 117.04447 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.14e+04  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 80         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 1700       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 105        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 8500       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.000204   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 1699       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -5.36e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -182.67564 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 8.78e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m day: 484, episode: 20\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m end_total_asset: 4206800.01\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_reward: 3206800.01\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_cost: 22626.54\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_trades: 30745\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m Sharpe: 2.817\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 80        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 1800      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 111       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 9000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -8.77e-05 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 1799      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 1.68e+04  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 20.985132 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.29e+04  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 82        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 1900      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 115       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 9500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.000302  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 1899      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -4.32e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -109.6891 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 2.12e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 83        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 2000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 119       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 10000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.000851  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 1999      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.16e+04 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 46.75838  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 8.32e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 82        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 2100      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 127       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 10500     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 2099      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.14e+04 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 81.66445  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 6.78e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m ------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 80       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 2200     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 136      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 11000    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 2199     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 4.01e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 92.51513 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 2.95e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m ------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 79        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 2300      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 145       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 11500     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 1.19e-07  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 2299      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -3.94e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 65.871445 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 2.5e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 74        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 2400      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 160       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 12000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 3.55e-05  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 2399      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -5.63e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 3.2167149 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 6.68e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 71        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 2500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 174       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 12500     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 2499      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.1e+04  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -65.92309 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 5.66e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 69        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 2600      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 187       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 13000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.000637  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 2599      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 2.43e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 42.110657 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 5.63e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 65        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 2700      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 204       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 13500     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -1.19e-07 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 2699      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 2.31e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -178.9874 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 8.06e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m day: 484, episode: 30\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m end_total_asset: 5841889.82\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_reward: 4841889.82\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_cost: 9875.79\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_trades: 29519\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m Sharpe: 2.624\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 64        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 2800      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 217       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 14000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 1.19e-07  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 2799      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -5.89e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 56.560936 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 2.6e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 64         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 2900       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 223        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 14500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.00408   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 2899       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -7.31e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -37.460964 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 4.56e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 65        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 3000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 228       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 15000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.00192   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 2999      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 1.98e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 20.039854 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 2.25e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m ------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 66       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 3100     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 234      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 15500    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 3099     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -407     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 71.12539 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 282      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m ------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 66        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 3200      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 239       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 16000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.00362  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 3199      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -2.58e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 71.225784 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.41e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 66         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 3300       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 247        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 16500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.0426    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 3299       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.04e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -2.3313732 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 56.1       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m ------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 67       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 3400     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 253      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 17000    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.184   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 3399     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -440     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 34.79168 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 53.8     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m ------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 65        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 3500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 268       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 17500     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.0104    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 3499      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.53e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 26.643526 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 426       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 62        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 3600      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 285       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 18000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.0419   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 3599      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 3.35e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 22.412981 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 710       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m day: 484, episode: 40\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m end_total_asset: 2888469.32\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_reward: 1888469.32\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_cost: 3690.20\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_trades: 28313\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m Sharpe: 2.751\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m ------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 60       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 3700     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 306      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 18500    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.053    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 3699     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 8.22e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 53.59883 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 2.96e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m ------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 58        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 3800      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 323       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 19000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.0214   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 3799      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.03e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 7.8867655 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 279       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 57        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 3900      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 341       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 19500     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.0173    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 3899      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.81e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 27.290318 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 227       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 57        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 4000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 346       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 20000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 3999      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -2.31e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -31.97694 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.02e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 58        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 4100      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 351       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 20500     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.0162    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 4099      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -4.37e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 7.6702285 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.01e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 59         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 4200       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 355        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 21000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 8.89e-05   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 4199       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 1.03e+04   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -41.298557 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 4.55e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 59        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 4300      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 359       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 21500     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.0104   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 4299      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 1.99e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 32.170696 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 280       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 60         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 4400       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 363        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 22000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.00381    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 4399       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 3.68e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -103.54687 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 878        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 61        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 4500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 367       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 22500     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 2.38e-07  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 4499      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 8.37e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 12.869818 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 2.98e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 61         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 4600       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 373        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 23000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -162       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 4599       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -622       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -7.1540327 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 192        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m day: 484, episode: 50\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m end_total_asset: 2340331.43\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_reward: 1340331.43\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_cost: 3897.63\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_trades: 27323\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m Sharpe: 2.728\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 61        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 4700      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 380       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 23500     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 4699      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.75e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -99.82974 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.14e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 62        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 4800      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 386       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 24000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -1.19e-07 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 4799      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -6.51e+03 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 53.513813 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.84e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 62        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 4900      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 391       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 24500     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -162      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 4899      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 9.8e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 62.780346 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 2.33e+04  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 63        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 5000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 395       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 25000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -3.58e-07 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 4999      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 1.55e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -21.5116  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 679       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 63        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 5100      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 399       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 25500     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 5099      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.17e+04 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 3.377562  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 7.41e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 64         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 5200       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 403        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 26000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -1.19e-07  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 5199       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 2.87e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -60.954445 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.45e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 64         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 5300       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 409        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 26500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -162       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 1.19e-07   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 5299       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 4.56e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -78.029884 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 3.29e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 65         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 5400       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 413        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 27000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -162       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 5399       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -9.19e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -3.1402347 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 3.82e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 64         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 5500       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 426        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 27500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -162       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.004      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 5499       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.51e+04  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -58.434967 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 9.18e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 63        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 5600      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 439       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 28000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -161      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.0165   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 5599      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 1.51e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 38.559803 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.55e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m day: 484, episode: 60\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m end_total_asset: 2773974.65\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_reward: 1773974.65\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_cost: 2538.08\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m total_trades: 26349\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m Sharpe: 2.806\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 63         |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 5700       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 447        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 28500      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |            |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -162       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0.0218     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 5699       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 1.28e+04   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -76.732834 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 8.44e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m --------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 63        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 5800      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 453       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 29000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -162      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -0.0167   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 5799      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | 2.44e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | -6.148374 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.78e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m ------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 64       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 5900     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 459      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 29500    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |          |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -162     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | 0        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 5899     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -3e+03   |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 14.90646 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 1.4e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m ------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | time/                 |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    fps                | 64        |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    iterations         | 6000      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    time_elapsed       | 465       |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    total_timesteps    | 30000     |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m | train/                |           |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    entropy_loss       | -162      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    explained_variance | -1.19e-07 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    learning_rate      | 0.0007    |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    n_updates          | 5999      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    policy_loss        | -1.33e+04 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    reward             | 14.988492 |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    std                | 1.01      |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m |    value_loss         | 7.34e+03  |\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m -------------------------------------\n",
      "Shutting down Ray to refresh memory...\n",
      "\u001b[36m(model_pretraining pid=17823)\u001b[0m Completed model agent_a2c.\n",
      "Model agent_a2c pretraining completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 10:08:46,767\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-12-23 10:08:50,704\tINFO worker.py:1652 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitializing Ray...\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m Finance Dimension: 113, State Space: 1248\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m Pretraining model from agent_ddpg...\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m {'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m Using cpu device\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m Logging to results/ddpg\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 4         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 10        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 190       |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 1940      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -10.6     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 38.3      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 1839      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m day: 484, episode: 10\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m end_total_asset: 1359438.67\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_reward: 359438.67\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_cost: 1041.69\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_trades: 23238\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m Sharpe: 1.838\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 8         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 8         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 462       |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 3880      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -9.21     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 5.67      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 3779      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 12        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 8         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 684       |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 5820      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -6.22     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 1.27      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 5719      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 16        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 9         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 855       |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 7760      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -13.9     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 2.87      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 7659      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m day: 484, episode: 20\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m end_total_asset: 1359438.67\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_reward: 359438.67\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_cost: 1041.69\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_trades: 23238\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m Sharpe: 1.838\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 20        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 9         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 1037      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 9700      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -9.43     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 0.575     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 9599      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 24        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 9         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 1283      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 11640     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -10.6     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 0.851     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 11539     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m day: 484, episode: 30\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m end_total_asset: 1359438.67\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_reward: 359438.67\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_cost: 1041.69\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_trades: 23238\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m Sharpe: 1.838\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 28        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 8         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 1529      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 13580     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -13.1     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 0.393     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 13479     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 32        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 8         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 1809      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 15520     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -14.3     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 0.576     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 15419     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 36        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 8         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 2050      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 17460     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -12       |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 1.36      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 17359     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m day: 484, episode: 40\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m end_total_asset: 1359438.67\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_reward: 359438.67\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_cost: 1041.69\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_trades: 23238\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m Sharpe: 1.838\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 40        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 8         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 2282      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 19400     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -10.1     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 0.32      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 19299     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 44        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 8         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 2518      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 21340     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -13.9     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 0.616     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 21239     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m day: 484, episode: 50\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m end_total_asset: 1359438.67\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_reward: 359438.67\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_cost: 1041.69\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_trades: 23238\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m Sharpe: 1.838\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 48        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 8         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 2680      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 23280     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -12.4     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 0.91      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 23179     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 52        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 8         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 2829      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 25220     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -15.7     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 0.596     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 25119     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 56        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 8         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 3279      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 27160     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -10.2     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 0.224     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 27059     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m day: 484, episode: 60\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m end_total_asset: 1359438.67\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_reward: 359438.67\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_cost: 1041.69\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m total_trades: 23238\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m Sharpe: 1.838\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    episodes        | 60        |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    fps             | 8         |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    time_elapsed    | 3402      |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    total_timesteps | 29100     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    actor_loss      | -11.9     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    critic_loss     | 0.433     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    learning_rate   | 0.001     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    n_updates       | 28999     |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m |    reward          | 54.557926 |\n",
      "\u001b[36m(model_pretraining pid=19397)\u001b[0m ----------------------------------\n",
      "Shutting down Ray to refresh memory...\n",
      "Model agent_ddpg pretraining completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 11:06:42,547\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-12-23 11:06:43,663\tINFO worker.py:1652 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitializing Ray...\n",
      "\u001b[36m(model_pretraining pid=21745)\u001b[0m Finance Dimension: 113, State Space: 1248\n",
      "\u001b[36m(model_pretraining pid=21745)\u001b[0m Pretraining model from agent_sac...\n",
      "\u001b[36m(model_pretraining pid=21745)\u001b[0m {'batch_size': 256, 'buffer_size': 1000000, 'learning_rate': 0.05, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "\u001b[36m(model_pretraining pid=21745)\u001b[0m Using cpu device\n",
      "\u001b[36m(model_pretraining pid=21745)\u001b[0m Logging to results/sac\n",
      "Shutting down Ray to refresh memory...\n",
      "Model agent_sac pretraining completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 11:08:11,906\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-12-23 11:08:13,380\tINFO worker.py:1652 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitializing Ray...\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m Finance Dimension: 113, State Space: 1248\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m Pretraining model from agent_td3...\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m {'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.01}\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m Using cpu device\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m Logging to results/td3\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    episodes        | 4         |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    fps             | 11        |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    time_elapsed    | 173       |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    total_timesteps | 1940      |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    actor_loss      | 20.6      |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    critic_loss     | 207       |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    learning_rate   | 0.01      |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    n_updates       | 1839      |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    reward          | 25.419582 |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m day: 484, episode: 10\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m begin_total_asset: 1000000.00\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m end_total_asset: 1237838.99\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m total_reward: 237838.99\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m total_cost: 999.00\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m total_trades: 24684\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m Sharpe: 1.238\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m =================================\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m ----------------------------------\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m | time/              |           |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    episodes        | 8         |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    fps             | 10        |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    time_elapsed    | 374       |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    total_timesteps | 3880      |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m | train/             |           |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    actor_loss      | 30.3      |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    critic_loss     | 45.2      |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    learning_rate   | 0.01      |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    n_updates       | 3779      |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m |    reward          | 25.419582 |\n",
      "\u001b[36m(model_pretraining pid=23205)\u001b[0m ----------------------------------\n"
     ]
    }
   ],
   "source": [
    "dict_ = {\n",
    "    'if_using_a2c' : True,\n",
    "    'if_using_ddpg' : True,\n",
    "    'if_using_sac' : True,\n",
    "    'if_using_td3' : True,\n",
    "} \n",
    "dt_anal.model_save(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce93448-85c3-4cbb-a1d8-d2dc033454d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
